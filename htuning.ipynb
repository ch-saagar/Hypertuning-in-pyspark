{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUH5B7E1X3h4",
        "outputId": "f5a64644-eea2-4f87-b38b-248ef3a3f7c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=88ed96b1aeaa8d1b417c00c4009a8287db391e455b3acc07341eca0e857679fc\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhqIUa_jXyWs",
        "outputId": "761c82c7-cf88-4f4b-fcfc-ed29adfd0b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession,SQLContext\n",
        "spark = SparkSession.builder.appName(\"Basics\").getOrCreate()\n",
        "sc=spark.sparkContext\n",
        "sqlContext = SQLContext(sc)\n",
        "df = sqlContext.range(0,10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, TimestampType\n",
        "df = (sqlContext.read.format(\"csv\").\n",
        "  option(\"header\", \"true\").\n",
        "  option(\"nullValue\", \"NA\").\n",
        "  option(\"inferSchema\", True).\n",
        "  load(\"flight_weather.csv\"))\n"
      ],
      "metadata": {
        "id": "LKFqEi33X3m1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "df = df.withColumn(\"ARR_DEL15\", when(df[\"CANCELLED\"] == 1, 1).otherwise(df[\"ARR_DEL15\"]))"
      ],
      "metadata": {
        "id": "Tuu7XFiUX3pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(df[\"DIVERTED\"] == 0)"
      ],
      "metadata": {
        "id": "1rx6xUk1X3si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.select(\n",
        "  \"ARR_DEL15\",\n",
        "  \"MONTH\",\n",
        "  \"DAY_OF_WEEK\",\n",
        "  \"UNIQUE_CARRIER\",\n",
        "  \"ORIGIN\",\n",
        "  \"DEST\",\n",
        "  \"CRS_DEP_TIME\",\n",
        "  \"CRS_ARR_TIME\",\n",
        "  \"RelativeHumidityOrigin\",\n",
        "  \"AltimeterOrigin\",\n",
        "  \"DryBulbCelsiusOrigin\",\n",
        "  \"WindSpeedOrigin\",\n",
        "  \"VisibilityOrigin\",\n",
        "  \"DewPointCelsiusOrigin\",\n",
        "  \"RelativeHumidityDest\",\n",
        "  \"AltimeterDest\",\n",
        "  \"DryBulbCelsiusDest\",\n",
        "  \"WindSpeedDest\",\n",
        "  \"VisibilityDest\",\n",
        "  \"DewPointCelsiusDest\")"
      ],
      "metadata": {
        "id": "KjcIh_WcX3vL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "SF7ZI3y_aF-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "uniqueCarrierIndexer = StringIndexer(inputCol=\"UNIQUE_CARRIER\", outputCol=\"Indexed_UNIQUE_CARRIER\").fit(df)\n",
        "originIndexer = StringIndexer(inputCol=\"ORIGIN\", outputCol=\"Indexed_ORIGIN\").fit(df)\n",
        "destIndexer = StringIndexer(inputCol=\"DEST\", outputCol=\"Indexed_DEST\").fit(df)\n",
        "arrDel15Indexer = StringIndexer(inputCol=\"ARR_DEL15\", outputCol=\"Indexed_ARR_DEL15\").fit(df)\n"
      ],
      "metadata": {
        "id": "i63HHmFBaGJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(\n",
        "  inputCols = [\n",
        "    \"MONTH\",\n",
        "    \"DAY_OF_WEEK\",\n",
        "    \"Indexed_UNIQUE_CARRIER\",\n",
        "    \"Indexed_ORIGIN\",\n",
        "    \"Indexed_DEST\",\n",
        "    \"CRS_DEP_TIME\",\n",
        "    \"CRS_ARR_TIME\",\n",
        "    \"RelativeHumidityOrigin\",\n",
        "    \"AltimeterOrigin\",\n",
        "    \"DryBulbCelsiusOrigin\",\n",
        "    \"WindSpeedOrigin\",\n",
        "    \"VisibilityOrigin\",\n",
        "    \"DewPointCelsiusOrigin\",\n",
        "    \"RelativeHumidityDest\",\n",
        "    \"AltimeterDest\",\n",
        "    \"DryBulbCelsiusDest\",\n",
        "    \"WindSpeedDest\",\n",
        "    \"VisibilityDest\",\n",
        "    \"DewPointCelsiusDest\"],\n",
        "  outputCol = \"features\")"
      ],
      "metadata": {
        "id": "o_FGxp4WaGMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "classifier = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"ARR_DEL15\")"
      ],
      "metadata": {
        "id": "IbROdlAoaGOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "pipeline = Pipeline(stages=[uniqueCarrierIndexer, originIndexer, destIndexer, arrDel15Indexer, assembler, classifier])"
      ],
      "metadata": {
        "id": "HFscQVn4aWym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "from pyspark.ml.tuning import TrainValidationSplit\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "paramGrid = ParamGridBuilder() \\\n",
        " .addGrid(classifier.maxDepth, [10, 20, 30]) \\\n",
        " .addGrid(classifier.maxBins, [300, 400, 500]) \\\n",
        " .build()\n",
        "tvs = TrainValidationSplit(\n",
        "  estimator=pipeline,\n",
        "  estimatorParamMaps=paramGrid,\n",
        "  evaluator=MulticlassClassificationEvaluator(labelCol=\"ARR_DEL15\", predictionCol=\"prediction\"),\n",
        "  trainRatio=0.8)  \n",
        "model = tvs.fit(df)"
      ],
      "metadata": {
        "id": "AE-m1fhWX38w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(zip(model.validationMetrics, model.getEstimatorParamMaps()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV-iFKRJX3_n",
        "outputId": "1082879c-0559-480a-d470-4a2c6253c8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.7841309652955493,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300}),\n",
              " (0.787060946103388,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 400}),\n",
              " (0.7859328915523613,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 500}),\n",
              " (0.7599996074269006,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300}),\n",
              " (0.759396463557529,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 400}),\n",
              " (0.762372022613782,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 500}),\n",
              " (0.7472585136247918,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300}),\n",
              " (0.7495292034682052,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 400}),\n",
              " (0.7516210296151149,\n",
              "  {Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 30,\n",
              "   Param(parent='DecisionTreeClassifier_6215ea4e21b4', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 500})]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df10 = df.limit(10)\n",
        "model.bestModel.transform(df10)\\\n",
        "  .select(\"ARR_DEL15\", \"prediction\")\\\n",
        "  .show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuPQqBSnamCh",
        "outputId": "91d45bb1-01a4-4b48-f42c-6d3fcba4d71f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------+\n",
            "|ARR_DEL15|prediction|\n",
            "+---------+----------+\n",
            "|        0|       0.0|\n",
            "|        0|       0.0|\n",
            "|        0|       0.0|\n",
            "|        1|       0.0|\n",
            "|        0|       0.0|\n",
            "|        0|       0.0|\n",
            "|        0|       0.0|\n",
            "|        0|       0.0|\n",
            "|        1|       0.0|\n",
            "|        0|       0.0|\n",
            "+---------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIxWUpl1amQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dVy8QD4RamSt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}